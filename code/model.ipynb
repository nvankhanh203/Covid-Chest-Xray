{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "314989cc",
   "metadata": {},
   "source": [
    "### importing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "367b32e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.optimizers import Adam, Adamax\n",
    "from tensorflow.keras.metrics import Precision, Recall, Accuracy\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, Concatenate, GlobalAveragePooling2D, BatchNormalization\n",
    "output_size = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aae58b79",
   "metadata": {},
   "source": [
    "### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba868a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data preprocessing\n",
    "\n",
    "train_dir=\"F:/khanh_covid/split_data/train\"\n",
    "val_dir='F:/khanh_covid/split_data/val'\n",
    "test_dir='F:/khanh_covid/split_data/test'\n",
    "\n",
    "train_datagen2=ImageDataGenerator(rescale=1.0/255,\n",
    "                                  horizontal_flip = True,\n",
    "                                  vertical_flip = True,\n",
    "                                  rotation_range = 20,\n",
    "                                  zca_whitening = True,\n",
    "                                  width_shift_range = 0.2,\n",
    "                                  height_shift_range = 0.2,\n",
    "                                  zoom_range = 0.2,\n",
    "                                 )\n",
    "\n",
    "val_datagen2=ImageDataGenerator(rescale=1.0/255,\n",
    "                                )\n",
    "\n",
    "test_datagen2=ImageDataGenerator(rescale=1.0/255,\n",
    "                                 )\n",
    "\n",
    "train_generator2=train_datagen2.flow_from_directory(train_dir,target_size=(224,224),batch_size=128,class_mode='binary')\n",
    "\n",
    "val_generator2=val_datagen2.flow_from_directory(val_dir,target_size=(224,224),batch_size=128,class_mode='binary')\n",
    "\n",
    "test_generator2=test_datagen2.flow_from_directory(test_dir,target_size=(224,224),batch_size=128,class_mode='binary')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47eb343e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_generator2.class_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bb76250",
   "metadata": {},
   "source": [
    "### VGG16 Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcd66fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vgg16 modify\n",
    "base_model = tf.keras.applications.VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "freezing = True\n",
    "if freezing:\n",
    "    for layer in base_model.layers[:-4]:\n",
    "        layer.trainable = False\n",
    "   \n",
    "    for layer in base_model.layers[-4:]:\n",
    "        print(layer.name)\n",
    "        layer.trainable = True\n",
    "        \n",
    "# output layers\n",
    "\n",
    "model = Flatten()(base_model.output)\n",
    "model = Dropout(0.3)(model)\n",
    "model = Dense(1024, activation='relu')(model)\n",
    "model = Dropout(0.25)(model)\n",
    "model = Dense(output_size, activation='sigmoid')(model)\n",
    "\n",
    "model = tf.keras.Model(inputs = base_model.input, outputs = model)\n",
    "\n",
    "loss_fn = tf.keras.losses.BinaryCrossentropy(label_smoothing=0.05)\n",
    "optimizer = Adam(learning_rate=5e-6, amsgrad=True)\n",
    "\n",
    "model.compile(optimizer=optimizer, loss=loss_fn, metrics=['accuracy', tf.keras.metrics.Precision(), tf.keras.metrics.Recall()])\n",
    "\n",
    "# Print model summary\n",
    "# model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba370ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train\n",
    "import pickle\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "# Tạo callback ModelCheckpoint để lưu model tại epochs tốt nhất của val_loss\n",
    "checkpoint = ModelCheckpoint('F:/khanh_covid/model/vgg16_modify_last_state.keras', monitor='val_loss', save_best_only=True, verbose=1)\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, verbose=1)\n",
    "\n",
    "history = model.fit(train_generator2,\n",
    "          validation_data=val_generator2,\n",
    "          epochs=40,     \n",
    "          callbacks=[early_stopping, checkpoint])\n",
    "\n",
    "\n",
    "with open('F:/khanh_covid/model/vgg16_modify_last_state.pkl', 'wb') as file:\n",
    "    pickle.dump(history.history, file)\n",
    "\n",
    "vgg16 = tf.keras.models.load_model('F:/khanh_covid/model/vgg16_modify_last_state.keras')\n",
    "eval_result = vgg16.evaluate(test_generator2, steps=624)\n",
    "eval_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3baf2a2f",
   "metadata": {},
   "source": [
    "### DenseNet121 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "208b1e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  DenNet101 model\n",
    "# load Densnet121 transfer learning\n",
    "base_model = tf.keras.applications.DenseNet121(weights='imagenet', include_top=False, input_shape=(224,224,3))\n",
    "\n",
    "# freeze all denselayers of the blocks except denselayer15, 16 of block4\n",
    "freezing_layer = True\n",
    "if freezing_layer:\n",
    "    for layer in base_model.layers[:-114]:\n",
    "        layer.trainable = False\n",
    "     \n",
    "    for layer in base_model.layers[-114:]:\n",
    "        # print(layer.name)\n",
    "        layer.trainable = True\n",
    "\n",
    "# output layers\n",
    "model = layers.GlobalAveragePooling2D()(base_model.output)\n",
    "model = layers.Dropout(0.25)(model)\n",
    "model = layers.Dense(output_size, activation='sigmoid')(model)\n",
    "\n",
    "model = tf.keras.Model(inputs = base_model.input, outputs = model)\n",
    "\n",
    "# loss\n",
    "loss_fn = tf.keras.losses.BinaryCrossentropy(label_smoothing=0.05)\n",
    "optimizer = Adam(learning_rate=5e-6, amsgrad=True)\n",
    "\n",
    "model.compile(optimizer=optimizer, loss=loss_fn, metrics=['accuracy', tf.keras.metrics.Precision(), tf.keras.metrics.Recall()])\n",
    "\n",
    "# Print model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "243b733f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "# Tạo callback ModelCheckpoint để lưu model tại epochs tốt nhất của val_loss\n",
    "checkpoint = ModelCheckpoint('F:/khanh_covid/model/dense_net121.keras', monitor='val_loss', save_best_only=True, verbose=1)\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, verbose=1)\n",
    "\n",
    "history = model.fit(train_generator2,\n",
    "          validation_data=val_generator2,\n",
    "          epochs=40,     \n",
    "          callbacks=[early_stopping, checkpoint])\n",
    "\n",
    "\n",
    "with open('F:/khanh_covid/model/dense_net121.pkl', 'wb') as file:\n",
    "    pickle.dump(history.history, file)\n",
    "\n",
    "dense_net121 = tf.keras.models.load_model('F:/khanh_covid/model/dense_net121.keras')\n",
    "eval_result = dense_net121.evaluate(test_generator2, steps=624)\n",
    "eval_result"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
